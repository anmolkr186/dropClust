{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import math\n",
    "import anndata2ri\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "import GenSA\n",
    "import scipy\n",
    "from scipy.optimize import dual_annealing\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "from igraph import *\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys\n",
    "import leidenalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimised_param(partition, nsamples = 500):\n",
    "    if(nsamples> partiton.shape[0]):\n",
    "        nsamples = partiton.shape[0]\n",
    "    \n",
    "    global_min = 0\n",
    "    tol = 1e-3\n",
    "    max_time = 20\n",
    "    lower = np.array([0.05, 0.9, 500])\n",
    "    upper = np.array([0.1, 0.95, 4000])\n",
    "    \n",
    "    params = None\n",
    "    \n",
    "    def pin_find(params, max_c = nsamples):\n",
    "        output = np.array(partition, dtype = float)\n",
    "        pinit = params[0]\n",
    "        pfin = params[1]\n",
    "        K = params[2]\n",
    "        cluster_freq = np.array(np.unique(output[:][1], return_counts=True).T)\n",
    "        prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "        cluster_freq = np.vstack(cluster_freq, prop).T\n",
    "        \n",
    "        subsamples_lovain = []\n",
    "        for i in range(len(prop)):\n",
    "            subsamples_lovain = subsamples_lovain + np.random.choice(output[np.nonzero(output[:][1]==i)][0], size = prop[k], replace = False)\n",
    "\n",
    "        subsamples_lovain = np.asarray(subsamples_lovain)\n",
    "        \n",
    "        return np.abs(max_c - subsamples_lovain.shape[0]) \n",
    "\n",
    "        # FIX ME: numpy.reshape() of some kind to be done here\n",
    "        # prop = reshape2::melt(prop)$value\n",
    "        \n",
    "    \n",
    "#     out = dual_annealing(func=pin_find, x0 = params, bounds = list(zip(lower, uppper)), seed=1234)\n",
    "    \n",
    "    out = gensa(func = pin_find, x0 = params, bounds = list(zip(lower, uppper)), maxtime = max_time, know_real = True, real_threshold =  global_min + tol)\n",
    "    \n",
    "#     print(out)\n",
    "    \n",
    "    return np.asarray((out.fun, out.x, out.nfev))\n",
    "\n",
    "def annPartition(data):\n",
    "    f = data.shape[0]\n",
    "    print(\"datashpae\",data.shape)\n",
    "    print(\"Building graphs with\", data.shape[1], \"nodes...\")\n",
    "    t = AnnoyIndex(f, 'angular')\n",
    "    for i in range(data.shape[1]):\n",
    "        v = data[:,i]\n",
    "        t.add_item(i, v)\n",
    "    \n",
    "    t.build(30)\n",
    "    \n",
    "    get_nn = lambda x: t.get_nns_by_item(x, 6)\n",
    "\n",
    "    indices = list(map(get_nn, np.arange(data.shape[1])));\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "#     print(indices)\n",
    "    \n",
    "    fin = []\n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in indices[i]:\n",
    "            fin.append((i,j))\n",
    "    fin = np.array(fin)\n",
    "    g = Graph(fin)\n",
    "    G = g.simplify(multiple=False, loops = False)\n",
    "    print(\"Louvain Partition...\")\n",
    "    partition = G.community_leiden(objective_function = \"modularity\");\n",
    "#     print(partition.membership)\n",
    "    \n",
    "    dataMatrix = np.c_[np.arange(data.shape[1]),np.array(partition.membership)]\n",
    "\n",
    "    return dataMatrix\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx('hg19/', var_names='gene_symbols', cache=True)   \n",
    "# print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 32738)\n"
     ]
    }
   ],
   "source": [
    "ob = adata.X\n",
    "ob = scipy.sparse.csr_matrix.toarray(ob)\n",
    "print(ob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (adata)\n",
    "nsamples=500\n",
    "method = \"sps\"\n",
    "optm_parameters=False\n",
    "pinit=0.195\n",
    "pfin = 0.9\n",
    "K=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10913\n",
      "(10913,)\n",
      "[ 9022 14083 27597 ... 14156  8145 25504]\n"
     ]
    }
   ],
   "source": [
    "# if(nsamples>adata.shape[1]):\n",
    "#     return adata\n",
    "\n",
    "# if(method not in [\"random\", \"sps\"]):\n",
    "#     print(\"Method not found\")\n",
    "#     exit()\n",
    "\n",
    "no_samples = ob.shape[1]\n",
    "init = no_samples if no_samples < 20000 else min(20000,round(no_samples/3))\n",
    "print(init)\n",
    "\n",
    "# random sample of ids from sample = 0 to no_samples - 1 of size init\n",
    "sample_ids = np.random.choice(list(range(0, no_samples,1)), init) \n",
    "print(sample_ids.shape)\n",
    "print(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 10913)\n",
      "datashpae (2700, 10913)\n",
      "Building graphs with 10913 nodes...\n",
      "Louvain Partition...\n",
      "[[ 0  0]\n",
      " [ 1  0]\n",
      " [ 2  0]\n",
      " [ 3  0]\n",
      " [ 4  0]\n",
      " [ 5  7]\n",
      " [ 6  0]\n",
      " [ 7  0]\n",
      " [ 8  7]\n",
      " [ 9  0]\n",
      " [10 10]\n",
      " [11  0]\n",
      " [12 10]\n",
      " [13  0]\n",
      " [14  0]\n",
      " [15  0]\n",
      " [16  0]\n",
      " [17 10]\n",
      " [18  7]\n",
      " [19  0]\n",
      " [20  0]\n",
      " [21  1]\n",
      " [22  0]\n",
      " [23 10]\n",
      " [24  1]\n",
      " [25  0]\n",
      " [26  0]\n",
      " [27  0]\n",
      " [28  0]\n",
      " [29 10]\n",
      " [30  0]\n",
      " [31 10]\n",
      " [32  1]\n",
      " [33  0]\n",
      " [34  1]\n",
      " [35  1]\n",
      " [36  0]\n",
      " [37  0]\n",
      " [38  0]\n",
      " [39  1]\n",
      " [40  0]\n",
      " [41 10]\n",
      " [42  0]\n",
      " [43  0]\n",
      " [44  9]\n",
      " [45  1]\n",
      " [46  1]\n",
      " [47  0]\n",
      " [48  0]\n",
      " [49  0]\n",
      " [50  1]\n",
      " [51  0]\n",
      " [52  0]\n",
      " [53  3]\n",
      " [54  8]\n",
      " [55  0]\n",
      " [56  9]\n",
      " [57  1]\n",
      " [58  9]\n",
      " [59 10]\n",
      " [60  0]\n",
      " [61 10]\n",
      " [62  3]\n",
      " [63  0]\n",
      " [64 10]\n",
      " [65  0]\n",
      " [66  0]\n",
      " [67 10]\n",
      " [68 10]\n",
      " [69 10]\n",
      " [70  1]\n",
      " [71  0]\n",
      " [72  0]\n",
      " [73  0]\n",
      " [74  0]\n",
      " [75  0]\n",
      " [76  0]\n",
      " [77 10]\n",
      " [78 10]\n",
      " [79  4]\n",
      " [80  0]\n",
      " [81 10]\n",
      " [82  0]\n",
      " [83  0]\n",
      " [84  7]\n",
      " [85 10]\n",
      " [86  0]\n",
      " [87  6]\n",
      " [88  0]\n",
      " [89  5]\n",
      " [90 10]\n",
      " [91  1]\n",
      " [92 10]\n",
      " [93 10]\n",
      " [94  0]\n",
      " [95  4]\n",
      " [96  0]\n",
      " [97  7]\n",
      " [98 10]\n",
      " [99 10]]\n"
     ]
    }
   ],
   "source": [
    "if(method==\"sps\"):\n",
    "    \"\"\"\n",
    "    if(!any(reducedDimNames(object)==\"CComponents\"))\n",
    "        data = Log2Normalize(normcounts(object)[SingleCellExperiment::rowData(object)$HVG, sample_ids],return.sparse = FALSE)\n",
    "    else\n",
    "        data = as.matrix(normcounts(object)[, sample_ids])\n",
    "    \"\"\"\n",
    "    \n",
    "    data = normalize(ob)\n",
    "    data = np.take(ob, sample_ids, axis = 1)\n",
    "    print(data.shape)\n",
    "    \n",
    "    # return numpy array\n",
    "    partition = annPartition(data)\n",
    "\n",
    "    # ---- How to convert partition-----\n",
    "    # data = pd.Series([1, 1, 1, 2, 3, 3, 3, 3, 4, 4, 5])\n",
    "    # data.value_counts()\n",
    "\n",
    "\n",
    "    if(optm_parameters==True):\n",
    "        param = optimized_param(partition, nsamples)\n",
    "        pinit = param[0]\n",
    "        pfin = param[1]\n",
    "        K = param[2]\n",
    "        print(\"Optimized parameters:\\n\", param,\"\\n\")\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #old seed\n",
    "    \n",
    "    # frequeny table of partition[:][1]\n",
    "    cluster_freq = np.array(np.unique(partition[:][1], return_counts=True).T)\n",
    "    prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "    cluster_freq = np.vstack(cluster_freq, prop).T\n",
    "\n",
    "    # FIX ME: numpy.reshape() of some kind to be done here\n",
    "    # prop = reshape2::melt(prop)$value\n",
    "\n",
    "    subsample = []\n",
    "\n",
    "    for i in range(len(prop)):\n",
    "        subsample = subsample + np.random.choice(partition[np.nonzero(partition[:][1]==i)], size = prop[k], replace = False)\n",
    "\n",
    "    subsample = np.asarray(subsample)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "#     .Random.seed = oldseed\n",
    "#     SummarizedExperiment::colData(object)$Sampling = rep(FALSE, ncol(object))\n",
    "#     SummarizedExperiment::colData(object)$Sampling[sample_ids[subsamples]] =  TRUE\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(len(subsamples), \"Samples extracted.\\n\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Code below needs to be converted first\n",
    "\n",
    "    # elif(method==\"random\"):\n",
    "    #     \"\"\"\n",
    "    #     oldseed = .Random.seed\n",
    "    #     subsamples = sample(sample_ids, nsamples)\n",
    "    #     .Random.seed = oldseed\n",
    "    #     SummarizedExperiment::colData(object)$Sampling = rep(FALSE, ncol(object))\n",
    "    #     SummarizedExperiment::colData(object)$Sampling[subsamples] =  TRUE\n",
    "\n",
    "    #     \"\"\"\n",
    "    # else:\n",
    "    #     print(\"Invalid Sampling. Fallback to all samples\")\n",
    "    \n",
    "    \n",
    "    #object@metadata[[\"dropClust\"]] = c(unlist(object@metadata[[\"dropClust\"]]),\"Sampling\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
