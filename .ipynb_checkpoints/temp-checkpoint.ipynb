{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import math\n",
    "from GenSA import *\n",
    "import scipy\n",
    "from scipy.optimize import dual_annealing\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "from igraph import *\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annPartition(data):\n",
    "    f = data.shape[0]\n",
    "    print(\"datashpae\",data.shape)\n",
    "    print(\"Building graphs with\", data.shape[1], \"nodes...\")\n",
    "    t = AnnoyIndex(f, 'angular')\n",
    "    for i in range(data.shape[1]):\n",
    "        v = data[:,i]\n",
    "        t.add_item(i, v)\n",
    "    \n",
    "    t.build(30)\n",
    "    \n",
    "    get_nn = lambda x: t.get_nns_by_item(x, 6)\n",
    "\n",
    "    indices = list(map(get_nn, np.arange(data.shape[1])));\n",
    "    \n",
    "    indices = np.array(indices)\n",
    "#     print(indices)\n",
    "    \n",
    "    fin = []\n",
    "    for i in range(indices.shape[0]):\n",
    "        for j in indices[i]:\n",
    "            fin.append((i,j))\n",
    "    fin = np.array(fin)\n",
    "    g = Graph(fin)\n",
    "    G = g.simplify(multiple=False, loops = False)\n",
    "    print(\"Louvain Partition...\")\n",
    "    partition = G.community_leiden(objective_function = \"modularity\");\n",
    "#     print(partition.membership)\n",
    "    \n",
    "    dataMatrix = np.c_[np.arange(data.shape[1]),np.array(partition.membership)]\n",
    "    print(\"Done...\")\n",
    "\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_10x_mtx('hg19/', var_names='gene_symbols', cache=True)   \n",
    "# print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 32738)\n"
     ]
    }
   ],
   "source": [
    "ob = adata.X\n",
    "ob = scipy.sparse.csr_matrix.toarray(ob)\n",
    "print(ob.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (adata)\n",
    "nsamples=500\n",
    "method = \"sps\"\n",
    "optm_parameters=True\n",
    "pinit=0.195\n",
    "pfin = 0.9\n",
    "K=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10913\n",
      "(10913,)\n",
      "[12858 20362 21012 ... 14977 15212 31759]\n"
     ]
    }
   ],
   "source": [
    "# if(nsamples>adata.shape[1]):\n",
    "#     return adata\n",
    "\n",
    "# if(method not in [\"random\", \"sps\"]):\n",
    "#     print(\"Method not found\")\n",
    "#     exit()\n",
    "\n",
    "no_samples = ob.shape[1]\n",
    "init = no_samples if no_samples < 20000 else min(20000,round(no_samples/3))\n",
    "print(init)\n",
    "\n",
    "# random sample of ids from sample = 0 to no_samples - 1 of size init\n",
    "sample_ids = np.random.choice(list(range(0, no_samples,1)), init) \n",
    "print(sample_ids.shape)\n",
    "print(sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2700, 10913)\n",
      "datashpae (2700, 10913)\n",
      "Building graphs with 10913 nodes...\n",
      "Louvain Partition...\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# if(method==\"sps\"):\n",
    "\"\"\"\n",
    "if(!any(reducedDimNames(object)==\"CComponents\"))\n",
    "    data = Log2Normalize(normcounts(object)[SingleCellExperiment::rowData(object)$HVG, sample_ids],return.sparse = FALSE)\n",
    "else\n",
    "    data = as.matrix(normcounts(object)[, sample_ids])\n",
    "\"\"\"\n",
    "\n",
    "data = normalize(ob)\n",
    "data = np.take(ob, sample_ids, axis = 1)\n",
    "print(data.shape)\n",
    "\n",
    "# return numpy array\n",
    "partition = annPartition(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_param(partition, nsamples = 500):\n",
    "    if(nsamples> partition.shape[0]):\n",
    "        nsamples = partiton.shape[0]\n",
    "    \n",
    "    global_min = 0\n",
    "    tol = 1e-3\n",
    "    max_time = 20\n",
    "    lower = np.array([0.05, 0.9, 500])\n",
    "    upper = np.array([0.1, 0.95, 4000])\n",
    "    \n",
    "    params = None\n",
    "    \n",
    "    def pin_find(params, max_c = nsamples):\n",
    "        output = np.array(partition)\n",
    "        #print(output.shape)\n",
    "        pinit = params[0]\n",
    "        pfin = params[1]\n",
    "        K = params[2]\n",
    "        \n",
    "        unique_elements, counts_elements = np.unique(output[:,1], return_counts=True)\n",
    "        cluster_freq = np.asarray((counts_elements), dtype = int)\n",
    "        #print(cluster_freq)\n",
    "        prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "        #print(cluster_freq.shape, prop.shape)\n",
    "        cluster_freq = np.vstack((cluster_freq,prop)).T\n",
    "        #print(cluster_freq.shape)\n",
    "                \n",
    "        subsamples_lovain = np.empty((0))\n",
    "        \n",
    "        for i in range(len(prop)):\n",
    "            subsamples_lovain = np.concatenate((subsamples_lovain, np.random.choice( output[output[:,1]==i,0], size = int(prop[i]), replace = False)), axis = None)\n",
    "\n",
    "        #print((subsamples_lovain))\n",
    "        return np.abs(max_c - subsamples_lovain.shape[0]) \n",
    "\n",
    "        # FIX ME: numpy.reshape() of some kind to be done here\n",
    "        # prop = reshape2::melt(prop)$value\n",
    "    \n",
    "    #out = gensa(func = pin_find, x0 = params, bounds = list(zip(lower, upper)))\n",
    "    out = dual_annealing(func = pin_find, x0 = params, bounds = list(zip(lower, upper)))\n",
    "    \n",
    "    print(out)    \n",
    "    # returning best set of parameters\n",
    "    return out.x\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     fun: 891\n",
      " message: ['Maximum number of iteration reached']\n",
      "    nfev: 6073\n",
      "    nhev: 0\n",
      "     nit: 1000\n",
      "    njev: 0\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([5.01309616e-02, 9.00275704e-01, 5.00115805e+02])\n",
      "Optimized parameters:\n",
      " [5.01309616e-02 9.00275704e-01 5.00115805e+02] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n#old seed\\n\\n# frequeny table of partition[:][1]\\ncluster_freq = np.array(np.unique(partition[:][1], return_counts=True).T)\\nprop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\\ncluster_freq = np.vstack(cluster_freq, prop).T\\n\\n# FIX ME: numpy.reshape() of some kind to be done here\\n# prop = reshape2::melt(prop)$value\\n\\nsubsample = []\\n\\nfor i in range(len(prop)):\\n    subsample = subsample + np.random.choice(partition[np.nonzero(partition[:][1]==i)], size = prop[i], replace = False)\\n\\nsubsample = np.asarray(subsample)\\n\\n'"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- How to convert partition-----\n",
    "# data = pd.Series([1, 1, 1, 2, 3, 3, 3, 3, 4, 4, 5])\n",
    "# data.value_counts()\n",
    "\n",
    "if(optm_parameters==True):\n",
    "    param = optimized_param(partition, nsamples)\n",
    "    pinit = param[0]\n",
    "    pfin = param[1]\n",
    "    K = param[2]\n",
    "    print(\"Optimized parameters:\\n\", param,\"\\n\")\n",
    "\n",
    "# print(partition.shape)\n",
    "# unique_elements, counts_elements = np.unique(partition[:,1], return_counts=True)\n",
    "# cluster_freq = np.asarray((counts_elements), dtype = int)\n",
    "# #print(cluster_freq)\n",
    "# prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "# #print(cluster_freq.shape, prop.shape)\n",
    "# cluster_freq = np.vstack((cluster_freq,prop)).T\n",
    "# #print(cluster_freq.shape)\n",
    "\n",
    "# subsamples = np.empty((0))\n",
    "        \n",
    "# for i in range(len(prop)):\n",
    "#     subsamples = np.concatenate((subsamples, np.random.choice( partition[partition[:,1]==i,0], size = int(prop[i]), replace = False)), axis = None)\n",
    "\n",
    "\n",
    "# print(len(subsamples), \"Samples extracted.\\n\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#old seed\n",
    "\n",
    "# frequeny table of partition[:][1]\n",
    "cluster_freq = np.array(np.unique(partition[:][1], return_counts=True).T)\n",
    "prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "cluster_freq = np.vstack(cluster_freq, prop).T\n",
    "\n",
    "# FIX ME: numpy.reshape() of some kind to be done here\n",
    "# prop = reshape2::melt(prop)$value\n",
    "\n",
    "subsample = []\n",
    "\n",
    "for i in range(len(prop)):\n",
    "    subsample = subsample + np.random.choice(partition[np.nonzero(partition[:][1]==i)], size = prop[i], replace = False)\n",
    "\n",
    "subsample = np.asarray(subsample)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#     .Random.seed = oldseed\n",
    "#     SummarizedExperiment::colData(object)$Sampling = rep(FALSE, ncol(object))\n",
    "#     SummarizedExperiment::colData(object)$Sampling[sample_ids[subsamples]] =  TRUE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "1391 Samples extracted.\n",
      "\n",
      "10901\n"
     ]
    }
   ],
   "source": [
    "unique_elements, counts_elements = np.unique(partition[:,1], return_counts=True)\n",
    "cluster_freq = np.asarray((counts_elements), dtype = int)\n",
    "print(cluster_freq.shape)\n",
    "prop = np.round((pinit - np.exp(-cluster_freq/K) * (pinit - pfin) )* cluster_freq)\n",
    "\n",
    "# #print(cluster_freq.shape, prop.shape)\n",
    "cluster_freq = np.vstack((cluster_freq,prop)).T\n",
    "# #print(cluster_freq.shape)\n",
    "\n",
    "subsamples = np.empty((0))\n",
    "        \n",
    "for i in range(len(prop)):\n",
    "    subsamples = np.concatenate((subsamples, np.random.choice(partition[partition[:,1]==i,0], size = int(prop[i]), replace = False)), axis = None)\n",
    "\n",
    "subsamples = np.asarray(subsamples, dtype = int)\n",
    "\n",
    "print(len(subsamples), \"Samples extracted.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subsamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
